{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to btw2413 - IoT Applications","text":"<p>Here you'll find Installation Intructions for our classroom projects. We'll install almost everything with docker. Please be sure your docker-installation is working.</p>"},{"location":"le04/","title":"Topic","text":"<p>Here you'll find installation instructions for the TIG-Stack.</p>"},{"location":"le04/tig-stack-install/","title":"Installing TIG-Stack","text":"Installation of TIG-Stack <p>TIG:</p> <p>T - Telegraf</p> <p>I - InfluxDB</p> <p>G - Grafana</p>"},{"location":"le04/tig-stack-install/#overall-working-plan-for-the-classroom-project","title":"Overall working plan for the classroom project","text":"<ol> <li>Every student is installing the whole TIG-Stack locally on their Computer.</li> <li>At the end, sensor data should be visible in Influx-DB. For this configuration-files have to be modified.</li> <li>A Grafana - Dashboard should be created in order to see sensor-data. Experiment with the possibilities.</li> <li>As a class, we'll design a common mqtt-topic structure. This structure has to be implemented by every student</li> <li>A central TIG-Stack will be installed on a public VM</li> <li>A central Grafana-Dashboard will show all Air-Pressure values from all students</li> </ol>"},{"location":"le04/tig-stack-install/#first-step-esp32-ist-publishing-sensor-values-to-the-mqtt-broker","title":"First Step: ESP32 ist publishing sensor-values to the MQTT-Broker","text":"<p>Be sure your ESP32 is publishing sensor-data to the MQTT-Broker. Check it with MQTT-Explorer.</p>"},{"location":"le04/tig-stack-install/#second-step-install-tig-stack","title":"Second Step: Install TIG-Stack","text":""},{"location":"le04/tig-stack-install/#installation-directory","title":"Installation Directory","text":"<p>Note</p> <p>Create a dedicated installation-Directory, with e.g. <code>mkdir docker-TIG</code> Put all following files into this directory files</p>"},{"location":"le04/tig-stack-install/#docker-composeyml","title":"docker-compose.yml","text":"<p>We'll install the whole stack in one shot with docker. For this we need a <code>docker-compose.yml</code></p> docker-compose.yml<pre><code>services:\n  #  mosquitto:\n  #  image: eclipse-mosquitto:2.0.18\n  #  container_name: mosquitto\n  #  ports:\n  #    - 1883:1883\n  #  networks:\n  #    - influxdb_network\n  #  volumes:\n  #    - ./mosquitto.conf:/mosquitto/config/mosquitto.conf:ro  # Read-only config file\n  #    - mosquitto_data:/mosquitto/data  # Persistent data volume\n  #    - mosquitto_log:/mosquitto/log  # Persistent log volume\n  #  restart: unless-stopped\n\n  influxdb:\n    # image: influxdb:2.7.5-alpine\n    image: influxdb:2.7.11-alpine\n    container_name: influxdb\n    ports:\n      - 8086:8086\n    volumes:\n      - influxdb_data:/var/lib/influxdb2:rw\n      # Optional: Mount a custom InfluxDB configuration file\n      - influxdb_config:/etc/influxdb2:rw\n    env_file:\n      - influxdb.env\n    networks:\n      - influxdb_network\n    restart: unless-stopped\n\n  telegraf:\n    # image: telegraf:1.29.5-alpine\n    image: telegraf:1.33.3-alpine\n    container_name: telegraf\n    ports:\n      - 8125:8125\n    volumes:\n      # Mount your Telegraf configuration file (replace with your path)\n      - ./telegraf.conf:/etc/telegraf/telegraf.conf:ro\n    networks:\n      - influxdb_network\n    restart: unless-stopped\n    depends_on:\n      - influxdb\n\n  grafana:\n    # image: grafana/grafana:10.2.4\n    image: grafana/grafana:11.5.2\n    container_name: grafana\n    ports:\n      - 3000:3000\n    volumes:\n      - grafana_storage:/var/lib/grafana\n    env_file:\n    - grafana.env\n    networks:\n      - influxdb_network\n    restart: unless-stopped\n    depends_on:\n      - influxdb\n\n\nnetworks:\n  influxdb_network:\n\nvolumes:\n  #mosquitto_data:\n  #mosquitto_log:\n  influxdb_data:\n  influxdb_config:\n  grafana_storage:\n</code></pre>"},{"location":"le04/tig-stack-install/#grafanaenv","title":"grafana.env","text":"grafana.env<pre><code>GF_SECURITY_ADMIN_USER=admin\nGF_SECURITY_ADMIN_PASSWORD=5up3rS3crEt\n</code></pre>"},{"location":"le04/tig-stack-install/#influxdbenv","title":"influxdb.env","text":"influxdb.env<pre><code>DOCKER_INFLUXDB_INIT_MODE=setup\n\n# Environment variables used during the setup and operation of the stack\n\n# admin credentials\nDOCKER_INFLUXDB_INIT_USERNAME=admin\nDOCKER_INFLUXDB_INIT_PASSWORD=5up3rS3crEt\nDOCKER_INFLUXDB_INIT_ADMIN_TOKEN=13dfffaaf8da2c2f83f90d9c462975ddab3978bf2e489f99ff983db39e726694 # openssl rand -base64 32\n\n# Primary InfluxDB organization &amp; bucket definitions\nDOCKER_INFLUXDB_INIT_ORG=homeauto\nDOCKER_INFLUXDB_INIT_BUCKET=default\n\n# Primary InfluxDB bucket retention period\n\n# NOTE: Valid units are nanoseconds (ns), microseconds(us), milliseconds (ms)\n# seconds (s), minutes (m), hours (h), days (d), and weeks (w).\nDOCKER_INFLUXDB_INIT_RETENTION=30d\n\n\n# InfluxDB port &amp; hostname definitions\nDOCKER_INFLUXDB_INIT_PORT=8086\nDOCKER_INFLUXDB_INIT_HOST=influxdb\n</code></pre>"},{"location":"le04/tig-stack-install/#telegrafconf","title":"telegraf.conf","text":"<p>change it to your environment! See lines 143 ff !</p> telegraf.conf<pre><code># Telegraf Configuration\n#\n# Telegraf is entirely plugin driven. All metrics are gathered from the\n# declared inputs, and sent to the declared outputs.\n#\n# Plugins must be declared in here to be active.\n# To deactivate a plugin, comment out the name and any variables.\n#\n# Use 'telegraf -config telegraf.conf -test' to see what metrics a config\n# file would generate.\n#\n# Environment variables can be used anywhere in this config file, simply surround\n# them with ${}. For strings the variable must be within quotes (ie, \"${STR_VAR}\"),\n# for numbers and booleans they should be plain (ie, ${INT_VAR}, ${BOOL_VAR})\n\n\n# Global tags can be specified here in key=\"value\" format.\n[global_tags]\n  # dc = \"us-east-1\" # will tag all metrics with dc=us-east-1\n  # rack = \"1a\"\n  ## Environment variables can be used as tags, and throughout the config file\n  # user = \"$USER\"\n\n# Configuration for telegraf agent\n[agent]\n  ## Default data collection interval for all inputs\n  interval = \"10s\"\n  ## Rounds collection interval to 'interval'\n  ## ie, if interval=\"10s\" then always collect on :00, :10, :20, etc.\n  round_interval = true\n\n  ## Telegraf will send metrics to outputs in batches of at most\n  ## metric_batch_size metrics.\n  ## This controls the size of writes that Telegraf sends to output plugins.\n  metric_batch_size = 1000\n\n  ## Maximum number of unwritten metrics per output.  Increasing this value\n  ## allows for longer periods of output downtime without dropping metrics at the\n  ## cost of higher maximum memory usage.\n  metric_buffer_limit = 10000\n\n  ## Collection jitter is used to jitter the collection by a random amount.\n  ## Each plugin will sleep for a random time within jitter before collecting.\n  ## This can be used to avoid many plugins querying things like sysfs at the\n  ## same time, which can have a measurable effect on the system.\n  collection_jitter = \"0s\"\n\n  ## Collection offset is used to shift the collection by the given amount.\n  ## This can be be used to avoid many plugins querying constraint devices\n  ## at the same time by manually scheduling them in time.\n  # collection_offset = \"0s\"\n\n  ## Default flushing interval for all outputs. Maximum flush_interval will be\n  ## flush_interval + flush_jitter\n  flush_interval = \"10s\"\n  ## Jitter the flush interval by a random amount. This is primarily to avoid\n  ## large write spikes for users running a large number of telegraf instances.\n  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s\n  flush_jitter = \"0s\"\n\n  ## Collected metrics are rounded to the precision specified. Precision is\n  ## specified as an interval with an integer + unit (e.g. 0s, 10ms, 2us, 4s).\n  ## Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\".\n  ##\n  ## By default or when set to \"0s\", precision will be set to the same\n  ## timestamp order as the collection interval, with the maximum being 1s:\n  ##   ie, when interval = \"10s\", precision will be \"1s\"\n  ##       when interval = \"250ms\", precision will be \"1ms\"\n  ##\n  ## Precision will NOT be used for service inputs. It is up to each individual\n  ## service input to set the timestamp at the appropriate precision.\n  precision = \"0s\"\n\n  ## Log at debug level.\n  # debug = false\n  ## Log only error level messages.\n  # quiet = false\n\n  ## Log target controls the destination for logs and can be one of \"file\",\n  ## \"stderr\" or, on Windows, \"eventlog\".  When set to \"file\", the output file\n  ## is determined by the \"logfile\" setting.\n  # logtarget = \"file\"\n\n  ## Name of the file to be logged to when using the \"file\" logtarget.  If set to\n  ## the empty string then logs are written to stderr.\n  # logfile = \"\"\n\n  ## The logfile will be rotated after the time interval specified.  When set\n  ## to 0 no time based rotation is performed.  Logs are rotated only when\n  ## written to, if there is no log activity rotation may be delayed.\n  # logfile_rotation_interval = \"0h\"\n\n  ## The logfile will be rotated when it becomes larger than the specified\n  ## size.  When set to 0 no size based rotation is performed.\n  # logfile_rotation_max_size = \"0MB\"\n\n  ## Maximum number of rotated archives to keep, any older logs are deleted.\n  ## If set to -1, no archives are removed.\n  # logfile_rotation_max_archives = 5\n\n  ## Pick a timezone to use when logging or type 'local' for local time.\n  ## Example: America/Chicago\n  log_with_timezone = \"Europe/Zurich\"\n\n  ## Override default hostname, if empty use os.Hostname()\n  hostname = \"my_notebook\"\n  ## If set to true, do no set the \"host\" tag in the telegraf agent.\n  omit_hostname = false\n  # omit_hostname = true\n\n  ## Method of translating SNMP objects. Can be \"netsnmp\" (deprecated) which\n  ## translates by calling external programs snmptranslate and snmptable,\n  ## or \"gosmi\" which translates using the built-in gosmi library.\n  # snmp_translator = \"netsnmp\"\n\n  ## Name of the file to load the state of plugins from and store the state to.\n  ## If uncommented and not empty, this file will be used to save the state of\n  ## stateful plugins on termination of Telegraf. If the file exists on start,\n  ## the state in the file will be restored for the plugins.\n  # statefile = \"\"\n\n# Read metrics about cpu usage\n[[inputs.cpu]]\n  ## Whether to report per-cpu stats or not\n  percpu = true\n  ## Whether to report total system cpu stats or not\n  totalcpu = true\n  ## If true, collect raw CPU time metrics\n  collect_cpu_time = false\n  ## If true, compute and report the sum of all non-idle CPU states\n  ## NOTE: The resulting 'time_active' field INCLUDES 'iowait'!\n  report_active = false\n  ## If true and the info is available then add core_id and physical_id tags\n  core_tags = false\n\n  # Configuration for sending metrics to InfluxDB 2.0\n[[outputs.influxdb_v2]]\n  ## The URLs of the InfluxDB cluster nodes.\n  ##\n  ## Multiple URLs can be specified for a single cluster, only ONE of the\n  ## urls will be written to each interval.\n  ##   ex: urls = [\"https://us-west-2-1.aws.cloud2.influxdata.com\"]\n  urls = [\"http://192.168.222.22:8086\"]\n\n  ## Token for authentication.\n  token = \"13dfffaaf8da2c2f83f90d9c462975ddab3978bf2e489f99ff983db39e726694\"\n\n  ## Organization is the name of the organization you wish to write to.\n  organization = \"homeauto\"\n\n  ## Destination bucket to write into.\n  bucket = \"default\"\n#\n#\n[[inputs.mqtt_consumer]]\n  servers = [\"tcp://mqttbroker:1883\"]\n  topics = [\"btw2413/jaeggi/bme280/#\"]\n  username = \"here_mqttuser\"\n  password = \"mqttbroker_pw\"\n  data_format = \"value\"\n  data_type = \"float\"\n\n[[inputs.mqtt_consumer]]\n  servers = [\"tcp://mqttbroker:1883\"]\n  topics = [\"btw2413/jaeggi/bme680/#\"]\n  username = \"here_mqttuser\"\n  password = \"mqttbroker_pw\"\n  data_format = \"value\"\n  data_type = \"float\"\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n</code></pre>"},{"location":"le04/tig-stack-install/#start-all-docker-container","title":"Start all docker container","text":"<p><code>docker compose up -d</code></p> <p>Check, if container are running with</p> <p><code>docker ps -a</code></p> `docker ps -a` container running?"},{"location":"le04/tig-stack-install/#exploring-data-in-influxdb-data-explorer","title":"Exploring Data in InfluxDB Data Explorer","text":"<p>Open a web browser and navigate to http://localhost:8086. Login in to InfluxDB with the credentials defined in the influxdb.env configuration file.</p> <p>Then go to the \"Data Explorer\" tab: Here, you can explore the data that arrive from Telegraf and stored in InfluxDB, execute queries, and visualize metrics.</p>"},{"location":"le04/tig-stack-install/#configuring-influxdb-data-source-in-grafana","title":"Configuring InfluxDB Data Source in Grafana","text":"<p>Open a web browser and navigate to http://localhost:3000. Login in to Grafana with the credentials defined in the grafana.env configuration file.</p> <p>Open the menu from the top left-hand side and go to \"Connections\" &gt; \"Data Sources\" &gt; \"Add data source\". Choose \"InfluxDB\" as the type. Configure the following settings:</p> <ul> <li>Name: Provide a name for the data source.</li> <li>Query Language: Flux</li> <li>HTTP URL: http://influxdb:8086. or http://localhost:8086</li> <li>Auth: Basic auth</li> <li>Basic Auth Details: username and password defined in influxdb.env</li> <li>InfluxDB Details:<ul> <li>Organization: defined in influxdb.env</li> <li>Token: defined in influxdb.env</li> <li>Default Bucket: defined in influxdb.env</li> </ul> </li> </ul> <p>Click \"Save &amp; Test\" to verify the connection</p>"},{"location":"le04/tig-stack-install/#visualise-time-series-data-using-grafana","title":"Visualise time-series data using Grafana","text":"<p>In the InfluxDB Data Explorer, choose the data point you would like to plot, e.g. humidity, click first on \"Submit\" to explore and then to the \"SCRIPT EDITOR\" to view the Flux code.</p> <p>Copy this Flux code. In Grafana, create a new dashboard or open an existing one. </p> <p>Add a new panel to the dashboard and edit the panel. </p> <p>Under the \"Query\" tab, choose \"InfluxDB\" as the data source. </p> <p>Paste the copied Flux code into the query editor. </p> <p>Configure visualization options as needed and click \"Apply\" to save the panel configuration.</p> <p>see also here</p>"}]}